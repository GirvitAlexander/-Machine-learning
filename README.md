# -Machine-learning
## work-1

### Задание 1 

Предположим X и Y две случайные переменные, отражающие возраст и рост, соответственно. Рассмотрим случайную выборку из 20 наблюдений:

*X = (73, 67, 103, 65, 48, 63, 33, 9, 56, 61, 48, 113, 78, 70, 41, 65, 34, 60, 54, 107)*  
*Y = (173, 237, 154, 144, 140, 195, 168, 182, 191, 133, 174, 151, 198, 125, 179, 176, 189, 205, 182, 184)*

Необходимо:  

	A. Найти среднее, медиану и моду величины X  
	B. Найти дисперсию Y  
	C. Построить график нормального распределения для X  
	D. Найти вероятность того, что возраст больше 65  
	E. Найти двумерное мат. ожидания и ковариационную матрицу для этих двух величин  
	F. Определить корреляцию между X и Y  
	G. Построить диаграмму рассеяния, отображающая зависимость между возрастом и ростом.  

### Задание 2
Для следующего набора данных

|       | **X<sub>1</sub>** | **X<sub>2</sub>** | **X<sub>3</sub>** |
| :---: | :---------------: | :---------------: | :---------------: |
| **a** |        47         |        44        |        35         |
| **b** |        96         |        55         |        6        |
| **c** |        2        |        3        |        3        |

рассчитайте ковариационную матрицу и обобщенную дисперсию.

### Задание 3
Даны два одномерных нормальных распределения N<sub>a</sub> и N<sub>b</sub> с мат. ожиданиями 3, 7 и СКО 4, 3 соответственно.

  A. Для каждого из значения {4, 6} определите, какое из распределений сгенерировало значение с большей вероятностью.  
	B. Найди значение, которой могло быть сгенерировано обеими распределениями с равной вероятностью.

## work-2
### Задание 1 

Рассмотрим данные:

|       | x<sub>1</sub> | x<sub>2</sub> | x<sub>3</sub> | x<sub>4</sub> | x<sub>5</sub> | x<sub>6</sub> | x<sub>7</sub> | x<sub>8</sub> |
| :---: | :-----------: | :-----------: | :-----------: | :-----------: | :-----------: | :-----------: | :-----------: | :-----------: |
| **A** |      1.9       |       2.9      |       1.4      |      -1.4       |      2      |      -1.4      |      -2.9      |      2      |
| **B** |      -5       |       -6.4      |       -1.5      |      -1.3       |      -6.3      |      -0.4      |      -3.1      |      -5.8      |

Есть ядро (функция сходства):
![image](https://user-images.githubusercontent.com/47891469/206912964-c56ad983-bc6a-436c-be59-eeb91911754a.png)

1. Построить диаграмму рассеяния точек **x<sub>i</sub>** (оси подписать, пронумеровать точки)
2. Рассчитать ядерную матрицу

### Задание 2
Рассмотрим данные в виде матрицы **D**:

| ***X<sub>1</sub>*** | ***X<sub>2</sub>*** |
| :-----------------: | :-----------------: |
|         -46         |         -19         |
|         -72         |         132         |
|         -27         |         73         |
|         3         |         64         |
|         -50         |         145         |
|         -37         |         202         |
|         -49         |         9         |
|         -47         |         37         |

1. Построить диаграмму рассеяния (оси подписать, пронумеровать точки)

2. Рассчитайте среднее **μ** для матрицы **D**, ковариационную матрицу **Σ** для матрицы **D** и ковариационную матрицу **Σ<sub>c</sub>**  для центрированной матрицы **D**

3. Рассчитайте собственные числа и собственные вектора для матрицы **Σ<sub>c</sub>**

4. Выведите индекс (порядковый номер), соответствующий первой главной компоненте

5. Рассчитайте первый главный компонент. Постройте точечный график полученного вектора (добавить к каждой точке ее номер)

6. Используя PCA из библиотеки sklearn, получите первую главную компоненту для матрицы **D**. Постройте точечный график полученного вектора (пронумеровать точки)

7. Визуально сравните графики, полученные в пунктах **5** и **6**. Убедитесь в корректности выполнения преобразований. Сохранен ли порядок точек? 

   Выведите название оси графика из пункта 1, проекция данных на которую сравнима с результатами PCA преобразований

8. **μ** и **Σ** сверху задают нормальное распределение, из которого были сгенерированы точки. Постройте диаграмму рассеяния, которая позволит определить ориентацию / размеры облака точек, полученного с помощью 2-мерной функции плотности вероятности. 

   На отдельном линейном графике постройте графики функций плотностей вероятности отдельных компонентов 2-мерного нормального распределения
   
### Задание 3

1. Для данных и ядра из первого задания найдите первую главную компоненту при нелинейном преобразовании для заданного ядра. Постройте точечный график полученного вектора (добавить к каждой точке ее номер)
2. Используя KernelPCA из библиотеки sklearn с ядром Гаусса и гаммой = 1, получите первую главную компоненту для данных из первого задания. Постройте точечный график полученного вектора (добавить к каждой точке ее номер)
3. Визуально сравните графики, полученные в пунктах **1** и **2**. Определите, использование какого ядра (из первого задания или ядра Гаусса) позволяет, на ваш взгляд, лучше визуально выделить принадлежность точки к одному из двух кластеров

## work-3
### Задание 1 
Дан набор данных:

| tid              | itemset |
| ---------------- | ------- |
| *t<sub>1</sub>*  | *ABG*    |
| *t<sub>2</sub>*  | *ACG*    |
| *t<sub>3</sub>*  | *DFG*    |
| *t<sub>4</sub>*  | *BEG*    |
| *t<sub>5</sub>*  | *BCFG*    |
| *t<sub>6</sub>*  | *ABDEG*    |
| *t<sub>7</sub>*  | *DF*    |
| *t<sub>8</sub>*  | *ABCDG*    |
| *t<sub>9</sub>*  | *BCDEF*   |
| *t<sub>10</sub>* | *BCG*   |

#### Алгоритм Apriori
Минимальный уровень поддержки равен **3 / 10** 

1.1. *Самостоятельно* реализуйте алгоритм **Apriori** и продемонстрируйте, как алгоритм перебирает предложенный набор данных. Выведите результат работы алгоритма

1.2. Воспользуйтесь алгоритмом **Apriori** из библиотеки **MLxtend** и выведите результат его работы. Сравните результаты собственной и библиотечной реализации

#### Алгоритм FPGrowth
Минимальный уровень поддержки равен **5 / 10**

1.3.  *Самостоятельно* реализуйте алгоритм **FPGrowth** и продемонстрируйте, как алгоритм перебирает предложенный набор данных. Выведите результат работы алгоритма

1.4. Воспользуйтесь алгоритмом **FPGrowth** из библиотеки **MLxtend** и выведите результат его работы. Сравните результаты собственной и библиотечной реализации

### Задание 2
На рисунке представлена классификация различных продуктов. Каждый лист дерева это конкретный продукт, внутренний узел дерева представляет категорию продукта более верхнего уровня.

![image](https://user-images.githubusercontent.com/47891469/206912773-0a062b56-e61c-4637-8e32-9c618dbbdc7b.png)

Был получен следующий набор данных:

| tid  | itemset |
| ---- | ------- |
| *t<sub>1</sub>*  | *ABEFGI*    |
| *t<sub>2</sub>*  | *ABEFGI*    |
| *t<sub>3</sub>*  | *BEH*    |
| *t<sub>4</sub>*  | *BDFHI*    |
| *t<sub>5</sub>*  | *CDEFH*    |
| *t<sub>6</sub>*  | *EHI*    |
| *t<sub>7</sub>*  | *BHI*    |
| *t<sub>8</sub>*  | *DFH*    |
| *t<sub>9</sub>*  | *CDEFGI*   |
| *t<sub>10</sub>* | *ACDF*   |


Выполните следующие задание:

2.1. Каков размер области поиска наборов элементов, если ограничиваться только наборами, состоящими из простых элементов?

2.2. Минимальный уровень поддержки равен **6 / 10**. Найдите все часто встречающиеся наборы элементов, состоящие только из элементов высокого уровня в таксономии. Имейте в виду, что если в транзакции появляется простой элемент, предполагается, что все его предки высокого уровня также присутствуют в транзакции. При выполнении данного пункта воспользуйтесь собственной реализацией **Apriori**.

## work-4
Дан набор точек **D**:

|      | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
|**x**|-25.2|-45|-43.7|-40.9|-42.3|-18.9|-30.7|-31.2|-25.4|-42|
|**y**|35.1|32.2|29.2|29.9|31.6|41.3|34.1|34.4|37.8|32.8|

Количество кластеров k = **2**

Начальные средние значения (центры кластеров) M = **[(-32, 39), (-45, 24)]**

Порог сходимости ε = **0.01**

1.1 *Самостоятельно* реализуйте алгоритм **KMeans** для двумерных данных. Вычислите кластеры и их центры. 

Оформите этот пункт в виде функции. Функция должна возвращать найденные кластеры и новые центры кластеров. Каждый кластер должен содержать индексы точек, которые принадлежат этому кластеру

1.2 Постройте диаграмму рассеяния, на которой будут отображены все точки, их принадлежность кластеру, центры кластеров. 

Оформите этот пункт в виде функции. Принадлежность кластеру отобразить цветом точки. Все точки подписать. Точки центров кластеров выделить

1.3 Воспользуйтесь алгоритмом **KMeans** из библиотеки **sklearn** и выведите результат его работы. Сравните результаты собственной и библиотечной реализации

1.4 К исходным данным добавьте точку **(10, -17)** и повторно вычислите кластеры и их центры. Также постройте диаграмму рассеяния

## Задание 2

Дан набор значений **X** и вероятностей их принадлежности к кластерам *C<sub>1</sub>* и *C<sub>2</sub>*:

| *x*  | *P(C<sub>1</sub>\|x)* | *P(C<sub>2</sub>\|x)* |
| ---- | --------------------- | --------------------- |
|7|0|1|
|6.9|0|1|
|4.4|0|1|
|19.7|0.7|0.3|
|19.2|0.8|0.2|
|14.8|0.9|0.1|
|20.4|0.5|0.5|
|10.3|0|1|
|7.7|0|1|
|15.2|0.9|0.1|

2.1 Найдите оценку максимального правдоподобия для средних μ<sub>1</sub> и μ<sub>2</sub>

2.2 Пусть μ<sub>1</sub> = **16**, μ<sub>2</sub> = **9.4** и σ<sub>1</sub> = **1.5**, σ<sub>2</sub> = **4.5**. Априорные вероятности каждого кластера P(*C<sub>1</sub>*) = **0.6**, P(*C<sub>2</sub>*) = **0.4**.

Найдите вероятности принадлежности точки x = **14.3** к кластерам *C<sub>1</sub>* и *C<sub>2</sub>*

## Задание 3

Даны категориальные данные размерности 5:

|           | *X<sub>1</sub>* | *X<sub>2</sub>* | *X<sub>3</sub>* | *X<sub>4</sub>* | *X<sub>5</sub>* |
| --------------- | -------- | --------------- | --------------- | --------------- | --------------- |
|**x<sub>0</sub>**|1|1|1|1|1|
|**x<sub>1</sub>**|1|0|1|1|0|
|**x<sub>2</sub>**|0|1|0|1|0|
|**x<sub>3</sub>**|0|0|0|0|0|
|**x<sub>4</sub>**|0|0|1|1|0|
|**x<sub>5</sub>**|0|1|0|0|0|

Близость двух наблюдений определяется через количество совпадений и несовпадений значений признаков. Допустим, что n<sub>11</sub> это количество признаков, одновременной равных 1 для наблюдений x<sub>i</sub> и x<sub>j</sub>, и n<sub>10</sub> это количество признаков, равных 1 для наблюдения x<sub>i</sub> и в то же время равных 0 для наблюдения x<sub>j</sub>. По аналогии определяются n<sub>01</sub> и n<sub>00</sub>:

| x<sub>i</sub> \ x<sub>j</sub> |       1        |       0        |
| :---------------------------: | :------------: | :------------: |
|               1               | n<sub>11</sub> | n<sub>10</sub> |
|               0               | n<sub>01</sub> | n<sub>00</sub> |

Даны следующие метрики:

- Коэффициент простого совпадения
  ![image](https://user-images.githubusercontent.com/47891469/206912692-3feb31e8-09a3-4742-8406-2b512bb7b1b5.png)
  
- Коэффициент Жаккара
  ![image](https://user-images.githubusercontent.com/47891469/206912857-d1df748c-076a-4191-962d-90ee7d7f4bd7.png)

- Коэффициент Рассела и Рао
  ![image](https://user-images.githubusercontent.com/47891469/206912891-ad50c7b4-98a8-4309-9213-2555d7ff75d2.png)

*Самостоятельно* реализуйте алгоритм **AgglomerativeClustering** (агломеративная иерархическая кластеризация). В качестве результата выведите список кластеров, возникающих на каждом шаге работы алгоритма.

Выполните иерархическую кластеризации и постройте дендрограммы по результатам кластеризации для следующих параметров алгоритма:

3.1 Метод одиночной связи с метрикой **RC**

3.2 Метод полной связи с метрикой **SMC**

3.3 Метод средней связи с метрикой **JC**

На дендрограммах подпишите точки (по оси x) и уровни (по оси y)

## Задание 4

Дан рисунок:

![n5_7_1](https://user-images.githubusercontent.com/47891469/206912812-0c2290fe-85e7-49ec-b023-ad5d955592fe.PNG)

Даны следующие метрики:

![image](https://user-images.githubusercontent.com/47891469/206912908-662a18cb-c7ef-45d4-bf53-fd74c884417e.png)

*Самостоятельно* реализуйте алгоритм **DBSCAN**. В качестве результата выведите список кластеров **C**, базовых точек **O**, граничных точек **B**, выпавших точек (шумов) **N**. Постройте диаграмму рассеяния, на которой будут отображены все точки, отображена их принадлежность кластеру, а также выпавшие точки (вид диаграммы аналогичен диаграмме из задания 1.2)

Выполните кластеризацию и построение диаграмм для следующих параметров алгоритма:

4.1 Метрика **1**, ϵ = **2**, minPts = **2**

4.2 Метрика **2**, ϵ = **4**, minPts = **4**

4.3 Метрика **3**, ϵ = **2**, minPts = **6**

4.4 Метрика **4**, ϵ = **1**, minPts = **5**

4.5 Метрика **5**, ϵ = **3**, minPts = **4**

## work-5
### Задание 1 

Дан набор точек **S**:

| *x<sub>i</sub>* | *a<sub>1</sub>* | *a<sub>2</sub>* | *a<sub>3</sub>* | Class |
| ---- | ---- | ---- | ---- | ---- |
|*x<sub>0</sub>*|F|D|7.8|Y|
|*x<sub>1</sub>*|N|D|4.9|N|
|*x<sub>2</sub>*|N|V|5.4|N|
|*x<sub>3</sub>*|N|D|1.6|N|
|*x<sub>4</sub>*|N|D|6|N|
|*x<sub>5</sub>*|F|D|5.6|Y|
|*x<sub>6</sub>*|N|D|8.4|Y|
|*x<sub>7</sub>*|F|R|9.7|Y|
|*x<sub>8</sub>*|N|V|5.9|Y|
|*x<sub>9</sub>*|F|D|4.2|N|

1.1 *Самостоятельно* реализуйте алгоритм **NaiveBayes** (*наивный классификатор Байеса*) для **числовых** и **категориальных** признаков.

Необходимо реализовать функцию обучения классификатора на исходных данных, результат которой позволит в дальнейшем производить классификацию точек.

Заметьте, что в исходных данных атрибуты *a<sub>1</sub>* и *a<sub>2</sub>* являются категориальными признаками, а *a<sub>3</sub>* - числовым (непрерывным) признаком.

Также реализуйте функцию определения класса точки и вероятностей ее принадлежности к классам. На вход функции подается результат обучения NaiveBayes и точка в пространстве исходных данных.

Воспользовавшись реализованными функциями, обучите классификатор и определите классы и вероятности точек:

**(F,R,9.3),
(F,R,1),
(N,D,6.2)**.

### Задание 2

Дан набор точек **D**:

| *i* | *x<sub>i</sub>* | Class |
| ---- | ---- | ---- |
|0|(11.2, 5.8)|-1|
|1|(10.9, 5.3)|-1|
|2|(10.7, 5.8)|-1|
|3|(4.8, 1)|1|
|4|(3.5, 3.7)|1|
|5|(0.8, 6.1)|1|
|6|(5.6, 1.6)|1|
|7|(11.1, 6.3)|-1|
|8|(10.3, 6.1)|-1|
|9|(4.2, 1.4)|1|

2.1 Реализуйте алгоритм **LinearDiscriminant** (*линейный дискриминантный анализ*) для двух классов по шагам:

- рассчитайте μ<sub>+1</sub> и μ<sub>-1</sub> и также матрицу B - матрица межклассового разброса

- рассчитайте S<sub>+1</sub> и S<sub>-1</sub> и также матрицу S - матрица внутриклассового разброса

- найдите направление **w**, которое лучше всего дискриминирует классы

- на направлении **w** найдите точку, которая лучше всего делит классы

2.2 Определите класс точки **(6.1, 12.2)**

2.3 Постройте диаграмму рассеяния исходных данных. Подпишите точки. Выделите цветом принадлежность точки к одному из классов.  

Также выведите на диаграмме:

- точки центов классов, выделите их иным маркером и подпишите
- вектор **w**
- линию **k** в направлении **w**
- спроектированные на **k** центры классов
- доп. точку из пункта 2.2, цветом укажите принадлежность к классу
- линии проекций на **k** всех точек (исходных точек, центров, доп. точки)
- найденную в пункте 2.1 точку, которая лучше всего делит классы на **k**
